{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2e8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!DEPRECATED SCRIPT!: Merges and video-length are based on the raw-uncut videos in this script. \n",
    "To have an accurate estimate, we should consider the clip_end-clip-start tied to a unique clip_uid in the annotations.\n",
    "\n",
    "\n",
    "This notebook analysis the Ego4d Long-term Action Anticipation (LTA)\n",
    "splits separately. These are the annotated available subsets.\n",
    "The annotations are linked to the meta-data json through video_uid.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os.path as osp\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)       \n",
    "\n",
    "EXECUTE = False # __name__ == '__main__' and '__file__' in globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ea617",
   "metadata": {},
   "source": [
    "# Parsing dataframes from jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad44bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire dataset Meta-data DF\n",
    "meta_data_file_path = \"/fb-agios-acai-efs/Ego4D/ego4d_data/ego4d.json\"\n",
    "with open(meta_data_file_path, 'r') as meta_data_file:\n",
    "    meta_data_obj = json.load(meta_data_file)\n",
    "\n",
    "# Convert to DF\n",
    "pd.json_normalize(meta_data_obj) # L1 overview\n",
    "video_df = pd.json_normalize(meta_data_obj['videos'])\n",
    "\n",
    "if EXECUTE:\n",
    "    video_df.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a498c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fho_lta_debug_val.json', 'fho_lta_taxonomy.json', 'fho_lta_test_unannotated.json', 'fho_lta_train.json', 'fho_lta_train_10000.json', 'fho_lta_train_5000.json', 'fho_lta_val.json']\n",
      "  version    date                                        description  split  \\\n",
      "0     1.0  220217  Ego4d Long Term Anticipation Forecasting Annot...  train   \n",
      "\n",
      "                                               clips  \n",
      "0  [{'video_uid': '9c59e912-2340-4400-b2df-7db3d4...  \n"
     ]
    }
   ],
   "source": [
    "# Get annotation DF for Long Term Action Anticipation (LTA)\n",
    "MODE='train' # train/test/val\n",
    "\n",
    "annotation_file_names = [n.strip() for n in \"\"\"\n",
    "fho_lta_debug_val.json\n",
    "fho_lta_taxonomy.json\n",
    "fho_lta_test_unannotated.json\n",
    "fho_lta_train.json\n",
    "fho_lta_train_10000.json\n",
    "fho_lta_train_5000.json\n",
    "fho_lta_val.json\n",
    "\"\"\".split('\\n') if len(n)> 0]\n",
    "print(annotation_file_names)\n",
    "\n",
    "annotation_file_dir = \"/fb-agios-acai-efs/Ego4D/ego4d_data/v1/annotations\"\n",
    "annotation_file_name = {'train':\"fho_lta_train.json\",'val':'fho_lta_val.json','test':'fho_lta_test_unannotated.json'}[MODE]\n",
    "assert annotation_file_name in annotation_file_names\n",
    "annotation_file_path = osp.join(annotation_file_dir, annotation_file_name)\n",
    "\n",
    "with open(annotation_file_path, 'r') as annotation_file:\n",
    "    annotation_obj = json.load(annotation_file)\n",
    "    \n",
    "# Check out the annotations\n",
    "# print(annotation_obj.keys())\n",
    "print(pd.json_normalize(annotation_obj).head(n=20))\n",
    "\"\"\"\n",
    "The annotation entries indicate a unique action in a timeframe of a specific video.\n",
    "There are multiple clips 'clip_uid' (and hence actions) per 'video_uid', and multiple actions per clip_uid.\n",
    "e.g. search on video_uid '9c59e912-2340-4400-b2df-7db3d4066723', resulting in 74 unique clip_uids\n",
    "The 'action_idx'=k indicates the k-th action in that clip.\n",
    "\"\"\"\n",
    "\n",
    "# Convert clips to DF\n",
    "labeled_clips_df = pd.json_normalize(annotation_obj['clips'])\n",
    "\n",
    "# SELECT WHERE... examples for a single clip_id or video_uid\n",
    "# labeled_clips_df.loc[labeled_clips_df['clip_id'] == 1805] # SELECT WHERE...\n",
    "# labeled_clips_df.loc[labeled_clips_df['video_uid'] == '8b72b54f-f87c-4fdb-84dc-97e42ab111ac'] # SELECT WHERE...\n",
    "if EXECUTE:\n",
    "    print(labeled_clips_df.head(n=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13029025",
   "metadata": {},
   "source": [
    "# Looking into the meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8c3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-data summary per user\n",
    "# Group by user (fb_participant_id) and accumulate video_count/duration/scenarios\n",
    "# Null/unassigned users are omitted automatically\n",
    "\n",
    "scenarios_per_user_df = video_df.groupby(video_df['fb_participant_id'], as_index=False).agg({'scenarios':list,'video_uid':'count','duration_sec':'sum'})\n",
    "scenarios_per_user_df['scenarios'] = scenarios_per_user_df['scenarios'].apply(np.concatenate).apply(Counter) # FLATTEN\n",
    "scenarios_per_user_df = scenarios_per_user_df.rename(columns={\"video_uid\":\"video_count\"})\n",
    "\n",
    "if EXECUTE:\n",
    "    scenarios_per_user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aefbd1c",
   "metadata": {},
   "source": [
    "## About the annotations\n",
    "There is one entry per supervision-label. This may contain multiple clips and multiple video fragments.\n",
    "A clip can be a sub-video of the parent video (probably because some videos very long for continuous labeling). One clip_id has multiple entries for all actions happening in that clip.\n",
    "\n",
    "The action label is identified by ('verb','noun') or ('verb_label','noun_label'). Don't use 'action_idx', this indicates the 'action-idx'-th action in a clip (action counter)!\n",
    "\n",
    "Multiple actions can happen at the same time! (Overlap in clip time ranges)\n",
    "\n",
    "Through the video_uid we can link the annotations to the user. (Linking meta-data with the annotation-data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5a1327",
   "metadata": {},
   "source": [
    "# Linking the meta-data and annotation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e3df42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9645, 54)\n",
      "labels_df=(23610, 20)\n",
      "joined_df=(23610, 73) -> Good, should have same #rows as labels-df, only keys are extended with info from meta-data object, such as user id etc\n"
     ]
    }
   ],
   "source": [
    "# First link labels to videos - INNER JOIN of meta-object and labels-object\n",
    "joined_df = pd.merge(video_df, labeled_clips_df, on=\"video_uid\",validate=\"one_to_many\",how=\"inner\") # Inner-join (Intersection of  video-uid values)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(video_df.shape)\n",
    "    print(f\"labels_df={labeled_clips_df.shape}\")\n",
    "    print(f\"joined_df={joined_df.shape} -> Good, should have same #rows as labels-df, only keys are extended with info from meta-data object, such as user id etc\")\n",
    "    joined_df\n",
    "\n",
    "def duration_row_fn(x):\n",
    "    video_uid_list = x[0]\n",
    "    video_len_list = x[1]\n",
    "\n",
    "    uniqe_video_uid_list, idxs = np.unique(video_uid_list,return_index=True)\n",
    "    sum_unique_video_len = sum(np.asarray(video_len_list,dtype=np.float64)[idxs])\n",
    "\n",
    "    return sum_unique_video_len\n",
    "    \n",
    "# Then group by user and aggregate columns\n",
    "def group_innerjoin_by_user(joined_df):\n",
    "    user_df = joined_df.copy(deep=True).groupby(joined_df['fb_participant_id'], as_index=False).agg(\n",
    "        {'fb_participant_id':'first','scenarios':list,'verb':list,'noun':list, 'verb_label':list, 'noun_label':list,\n",
    "         'video_uid':list,'duration_sec':list,'clip_id':list,'action_idx':list,\n",
    "        'clip_parent_start_sec':list,'clip_parent_end_sec':list}) # VIDEO UID COUNT IS NOT CORRECT! Also counts non-uniques in join\n",
    "\n",
    "    user_df['rawvideo_duration_sec_sum'] = user_df.loc[:,('video_uid','duration_sec')].apply(duration_row_fn, axis=1)\n",
    "    user_df['video_count'] = user_df['video_uid'].apply(lambda x: len(np.unique(x))) # BUGFIX: we need only UNIQUE video_uids after inner_join\n",
    "    user_df['scenarios'] = user_df['scenarios'].apply(np.concatenate) # FLATTEN\n",
    "    user_df['action_count'] = user_df['action_idx'].apply(lambda x:len(x))\n",
    "    user_df.drop('duration_sec', axis=1, inplace=True) # Make sure we don't use this one further on\n",
    "    return user_df\n",
    "\n",
    "user_df = group_innerjoin_by_user(joined_df)\n",
    "\n",
    "if EXECUTE:\n",
    "    user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe057034",
   "metadata": {},
   "source": [
    "# Convert (verb,noun) into actions and create Counter-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b20eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created action_label column\n",
      "Created action column\n",
      "Created column Counter: action_label\n",
      "Created column Counter: action\n",
      "344\n"
     ]
    }
   ],
   "source": [
    "# MERGE (verb,noun) columns in_place\n",
    "def create_action_labels_from_verbnoun(user_df):\n",
    "    def label_fn(x):\n",
    "        assert len(x) == 2, \"Need two columns to merge\"\n",
    "        if not isinstance(x[0],list):\n",
    "            assert not isinstance(x[1],list)\n",
    "            return f\"{x[0]}-{x[1]}\"\n",
    "\n",
    "        return [f\"{l}-{r}\" for l,r in zip(x[0],x[1])]\n",
    "    \n",
    "    user_df['action_label'] = user_df.loc[:,('verb_label','noun_label')].apply(label_fn,axis=1)\n",
    "    print(\"Created action_label column\")\n",
    "    \n",
    "    user_df['action'] = user_df.loc[:,('verb','noun')].apply(label_fn, axis=1)\n",
    "    print(\"Created action column\")\n",
    "    \n",
    "# APPLY COUNTER OBJECTS ON ACTIONS\n",
    "def create_counter_columns(df, cols=('action_label','action')):\n",
    "    assert isinstance(cols,tuple)\n",
    "    for col in cols:\n",
    "        print(f\"Created column Counter: {col}\")\n",
    "        df[f\"{col}_count\"] = df[col].apply(Counter)\n",
    "        \n",
    "def get_normalized_distr_actions(user_action_freq_df, target_col='action_count',new_col='action_distr'):\n",
    "    user_action_freq_df[new_col] = user_action_freq_df[target_col].apply(\n",
    "        lambda x:sorted([el/sum(list(x.values())) for el in x.values()],reverse=True)\n",
    "    )\n",
    "\n",
    "    # Max nb of different scenarios for 1 user (for zero padding the rest for means/stds)\n",
    "    max_action_list_len = user_action_freq_df[new_col].apply(len).max()\n",
    "    print(max_action_list_len)\n",
    "\n",
    "    # Append zero counts for others\n",
    "    user_action_freq_df[new_col] = user_action_freq_df[new_col].apply(\n",
    "        lambda x:np.pad(x,(0,max_action_list_len - len(x)))\n",
    "    )\n",
    "\n",
    "# In-place operations\n",
    "create_action_labels_from_verbnoun(user_df)\n",
    "create_counter_columns(user_df)\n",
    "get_normalized_distr_actions(user_df)\n",
    "\n",
    "user_action_freq_df = user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ce518",
   "metadata": {},
   "source": [
    "# Summarize actions per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04eea466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 47.56886574074074 actions/video avgd over users\n",
      "video_df=(9645, 54), labels_df=(23610, 20)\n",
      "                               video_uid  \\\n",
      "0   002d2729-df71-438d-8396-5895b349e8fd   \n",
      "1   01db7c39-a512-4bac-b284-dff8c7360e80   \n",
      "2   02995fb6-f8ac-4168-a60d-8a0b1a7210bd   \n",
      "3   05e8b510-0973-4cbd-9a23-bf2c156b7958   \n",
      "4   05f672ea-1651-4767-9c8a-0f504805e9c7   \n",
      "5   062ded0e-1df8-42d1-adaa-fc948e1cd7de   \n",
      "6   078f6bad-aa22-48bf-9df2-4d2f6ba7b556   \n",
      "7   080657b3-7f23-4285-96ec-39136e58cdf1   \n",
      "8   0836e1a4-11e6-4b31-bd39-f8e083fdadb3   \n",
      "9   099f6f96-5aa7-4da8-a5e0-2e8bc03beee6   \n",
      "10  0b24eb9e-a5ae-4389-b2cd-11fbf88e9c4a   \n",
      "11  0b6fc89d-bf4b-44f3-82e7-67ee02517459   \n",
      "12  0be30efe-9d71-4698-8304-f1d441aeea58   \n",
      "13  0c192ca8-1ede-4ef0-a05e-2f4151b6bdfc   \n",
      "14  0c8c2f4b-a006-47ca-8826-133af1dfb632   \n",
      "15  0cb2dd94-afb1-4e30-a62f-724f34d81777   \n",
      "16  0d8a3e5c-4263-4f80-b32d-39d4f33008ba   \n",
      "17  0e6fb738-05fc-4dd5-9746-a8e10efe8c20   \n",
      "18  0fbf42b1-23ed-4a2b-ad71-ab438b45e0d2   \n",
      "19  0fe191ef-c28a-422c-aede-46f8aa8532a6   \n",
      "\n",
      "                                                 verb  \\\n",
      "0   [put_(place,_leave,_drop), take_(pick,_grab,_g...   \n",
      "1   [hold_(support,_grip,_grasp), cut_(trim,_slice...   \n",
      "2   [hit_(knock,_hit,_hammer), cut_(trim,_slice,_c...   \n",
      "3   [take_(pick,_grab,_get), adjust_(regulate,_inc...   \n",
      "4   [turn_(spin,_rotate,_flip,_turn_over), move_(t...   \n",
      "5   [hold_(support,_grip,_grasp), hold_(support,_g...   \n",
      "6   [hold_(support,_grip,_grasp), wear, cover, close]   \n",
      "7   [take_(pick,_grab,_get), move_(transfer,_pass,...   \n",
      "8   [turn_(spin,_rotate,_flip,_turn_over), take_(p...   \n",
      "9   [take_(pick,_grab,_get), clean_(sweep,_scrub,_...   \n",
      "10  [play, move_(transfer,_pass,_exchange), adjust...   \n",
      "11  [take_(pick,_grab,_get), close, put_(place,_le...   \n",
      "12  [clean_(sweep,_scrub,_mop,_dust), clean_(sweep...   \n",
      "13  [pull, put_(place,_leave,_drop), remove, put_(...   \n",
      "14  [put_(place,_leave,_drop), touch, lift, put_(p...   \n",
      "15  [wipe, wipe, touch, wipe, wipe, touch, touch, ...   \n",
      "16  [attach_(plug-in,_join,_fasten,_connect,_attac...   \n",
      "17  [clean_(sweep,_scrub,_mop,_dust), clean_(sweep...   \n",
      "18  [put_(place,_leave,_drop), move_(transfer,_pas...   \n",
      "19  [hold_(support,_grip,_grasp), scrape, mix, put...   \n",
      "\n",
      "                                                 noun  \\\n",
      "0   [lid_(cap,_cover,_lid), pepper_(vegetable)_(ca...   \n",
      "1   [shears, tree, branch, tree, tree, branch, tre...   \n",
      "2   [trimmer_(pruner,_trimmer), grass, trimmer_(pr...   \n",
      "3   [hose, hose, plant_(bud,_frond,_plant,_reed,_s...   \n",
      "4   [book_(book,_booklet,_magazine,_manual,_notebo...   \n",
      "5   [leg_(knee,_leg,_thigh), leg_(knee,_leg,_thigh...   \n",
      "6   [bag_(bag,_grocery,_nylon,_polythene,_pouch,_s...   \n",
      "7   [wire_(adapter,_cable,_charger,_connector,_cor...   \n",
      "8   [shelf, stick_(stick,_twig), shelf, stick_(sti...   \n",
      "9   [mat_(mat,_rug), tile, mat_(mat,_rug), shoe_(b...   \n",
      "10  [guitar, guitar, guitar, guitar, guitar, guita...   \n",
      "11  [plate_(dish,_plate,_platter,_saucer), door, p...   \n",
      "12  [rail_(rail,_railing), wood_(fiber,_firewood,_...   \n",
      "13  [tray, tray, cloth_(cloth,_fabric,_garment,_ka...   \n",
      "14  [cloth_(cloth,_fabric,_garment,_kanga,_rag), b...   \n",
      "15  [wood_(fiber,_firewood,_floorboard,_log,_lumbe...   \n",
      "16  [block_(material), mat_(mat,_rug), tray, lid_(...   \n",
      "17  [napkin_(handkerchief,_napkin,_serviette,_tiss...   \n",
      "18  [belt, lever, jack_(tool)_(jack,_lift), jack_(...   \n",
      "19  [scraper_(scraper,_scrapper), spoon_(spoon,_sp...   \n",
      "\n",
      "                                           verb_label  \\\n",
      "0   [65, 92, 49, 65, 67, 67, 92, 65, 92, 65, 67, 9...   \n",
      "1   [35, 16, 64, 16, 99, 64, 16, 64, 16, 16, 64, 6...   \n",
      "2   [34, 16, 34, 16, 16, 17, 35, 16, 49, 16, 34, 0...   \n",
      "3   [92, 0, 109, 100, 49, 65, 42, 65, 67, 65, 98, ...   \n",
      "4                    [99, 49, 49, 58, 49, 49, 58, 58]   \n",
      "5                    [35, 35, 98, 50, 65, 98, 65, 92]   \n",
      "6                                   [35, 110, 14, 11]   \n",
      "7        [92, 49, 49, 68, 50, 68, 49, 65, 49, 92, 61]   \n",
      "8   [99, 92, 72, 9, 65, 100, 92, 112, 65, 100, 11,...   \n",
      "9   [92, 9, 65, 65, 65, 9, 64, 64, 9, 9, 9, 92, 9,...   \n",
      "10    [58, 49, 0, 0, 58, 0, 58, 0, 0, 58, 58, 49, 58]   \n",
      "11  [92, 11, 65, 50, 65, 50, 65, 65, 76, 76, 92, 7...   \n",
      "12  [9, 9, 9, 9, 9, 9, 9, 9, 49, 9, 9, 9, 9, 9, 9,...   \n",
      "13  [62, 65, 67, 65, 67, 65, 92, 65, 65, 99, 65, 6...   \n",
      "14  [65, 98, 42, 65, 92, 49, 112, 65, 112, 84, 99,...   \n",
      "15  [112, 112, 98, 112, 112, 98, 98, 9, 9, 9, 9, 9...   \n",
      "16  [3, 94, 6, 42, 36, 94, 65, 67, 65, 67, 65, 67,...   \n",
      "17  [9, 9, 92, 49, 6, 0, 92, 65, 0, 67, 92, 0, 102...   \n",
      "18                                   [65, 49, 51, 23]   \n",
      "19  [35, 72, 47, 65, 49, 65, 35, 47, 65, 35, 11, 6...   \n",
      "\n",
      "                                           noun_label  \\\n",
      "0   [233, 299, 299, 299, 299, 299, 299, 299, 299, ...   \n",
      "1   [360, 439, 45, 439, 439, 45, 439, 45, 439, 439...   \n",
      "2   [440, 190, 440, 190, 190, 122, 199, 190, 122, ...   \n",
      "3   [211, 211, 312, 211, 211, 211, 364, 364, 439, ...   \n",
      "4                [38, 195, 38, 195, 38, 38, 195, 195]   \n",
      "5                  [230, 230, 10, 10, 10, 10, 40, 12]   \n",
      "6                                   [10, 10, 436, 10]   \n",
      "7   [468, 468, 23, 23, 324, 23, 324, 468, 468, 300...   \n",
      "8   [362, 399, 362, 399, 399, 150, 265, 265, 265, ...   \n",
      "9   [243, 422, 243, 365, 243, 447, 129, 129, 422, ...   \n",
      "10  [195, 195, 195, 195, 195, 195, 195, 195, 195, ...   \n",
      "11  [313, 129, 313, 166, 41, 41, 233, 41, 118, 118...   \n",
      "12  [328, 469, 469, 469, 328, 469, 328, 469, 80, 4...   \n",
      "13  [437, 437, 97, 97, 97, 97, 97, 97, 97, 97, 97,...   \n",
      "14  [97, 52, 375, 52, 97, 97, 66, 66, 66, 66, 66, ...   \n",
      "15  [469, 469, 279, 279, 469, 279, 279, 279, 279, ...   \n",
      "16  [35, 243, 437, 233, 233, 105, 105, 105, 105, 1...   \n",
      "17  [265, 265, 97, 97, 319, 319, 233, 319, 163, 39...   \n",
      "18                                [28, 232, 217, 217]   \n",
      "19  [351, 390, 163, 351, 286, 390, 199, 163, 351, ...   \n",
      "\n",
      "                                              clip_id  \\\n",
      "0   [1249, 1249, 1249, 1249, 1249, 1249, 1249, 124...   \n",
      "1   [660, 660, 660, 660, 660, 660, 660, 660, 660, ...   \n",
      "2   [1996, 1996, 1996, 1996, 1996, 1996, 1996, 199...   \n",
      "3   [2037, 2037, 2037, 2037, 2037, 2037, 2037, 203...   \n",
      "4    [2940, 2940, 2940, 2940, 2940, 2940, 2940, 2940]   \n",
      "5    [2091, 2091, 2091, 2091, 2091, 2091, 2091, 2091]   \n",
      "6                            [3102, 3102, 3102, 3102]   \n",
      "7   [1852, 1852, 1852, 1852, 1852, 1852, 1852, 185...   \n",
      "8   [1038, 1038, 1038, 1038, 1038, 1038, 1038, 103...   \n",
      "9   [846, 846, 846, 846, 846, 846, 846, 846, 846, ...   \n",
      "10  [2933, 2933, 2933, 2933, 2933, 2933, 2933, 293...   \n",
      "11  [1418, 1418, 1418, 1418, 1418, 1418, 1418, 141...   \n",
      "12  [2618, 2618, 2618, 2618, 2618, 2618, 2618, 261...   \n",
      "13  [133, 133, 133, 133, 133, 133, 133, 133, 133, ...   \n",
      "14  [602, 602, 602, 602, 602, 602, 602, 602, 602, ...   \n",
      "15  [2675, 2675, 2675, 2675, 2675, 2675, 2675, 267...   \n",
      "16  [2545, 2545, 2545, 2545, 2545, 2545, 2545, 254...   \n",
      "17  [1202, 1202, 1202, 1202, 1202, 1202, 1202, 120...   \n",
      "18                           [1850, 1850, 1850, 1850]   \n",
      "19  [1291, 1291, 1291, 1291, 1291, 1291, 1291, 129...   \n",
      "\n",
      "                                           action_idx  action_count  \n",
      "0   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            87  \n",
      "1   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            19  \n",
      "2          [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]            13  \n",
      "3   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            30  \n",
      "4                            [0, 1, 2, 3, 4, 5, 6, 7]             8  \n",
      "5                            [0, 1, 2, 3, 4, 5, 6, 7]             8  \n",
      "6                                        [0, 1, 2, 3]             4  \n",
      "7                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]            11  \n",
      "8   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            82  \n",
      "9   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            15  \n",
      "10         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]            13  \n",
      "11  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            27  \n",
      "12  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            33  \n",
      "13  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            92  \n",
      "14  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            22  \n",
      "15  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            61  \n",
      "16  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            64  \n",
      "17  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            36  \n",
      "18                                       [0, 1, 2, 3]             4  \n",
      "19  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...            45  \n",
      "All video_uid's in annotations exist in the meta data object = True\n"
     ]
    }
   ],
   "source": [
    "# Stats and checks on actions\n",
    "\n",
    "# Calculate on avg how many actions on avg per video\n",
    "# First avg over actions in video, then avg over users, or equivalent: #user-action/#user-videos\n",
    "user_action_freq_df['actions_per_video'] = user_action_freq_df.loc[:,('video_count','action_count')].apply(\n",
    "    lambda x: float(sum(x[1].values()))/float(x[0]), \n",
    "    axis=1)\n",
    "print(f\"We have {user_action_freq_df['actions_per_video'].mean()} actions/video avgd over users\")\n",
    "\n",
    "# Group labeled clips by unique_videos\n",
    "print(f\"video_df={video_df.shape}, labels_df={labeled_clips_df.shape}\")\n",
    "group_labeled_clips_df = labeled_clips_df.groupby(labeled_clips_df['video_uid'], as_index=False).agg(\n",
    "    {'verb':list,'noun':list, 'verb_label':list, 'noun_label':list,'clip_id':list,'action_idx':list})\n",
    "group_labeled_clips_df['action_count'] = group_labeled_clips_df['action_idx'].apply(lambda x: len(x))\n",
    "print(group_labeled_clips_df.head(n=20))\n",
    "\n",
    "# CHECK IF ALL ANNOTATION VIDEOS EXIST IN META-DATA DF\n",
    "print(\"All video_uid's in annotations exist in the meta data object = {}\".format(\n",
    "(group_labeled_clips_df.video_uid.isin(video_df.video_uid) == True).all()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d9e85",
   "metadata": {},
   "source": [
    "# Plot stacked barchart: Action distr per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "227d9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other visualisation: users on x-axis and y-axis is multi-barplot where scenarios ordered on freq\n",
    "def check_sum_one(list_of_distr):\n",
    "    eps = 1e-5\n",
    "    for distr in list_of_distr:\n",
    "        prob_sum = sum(distr)\n",
    "        assert 1-eps < prob_sum < 1 + eps, f\"prob_sum={prob_sum} NOT SUMMING TO ONE\"\n",
    "\n",
    "def plot_useractions_stackedbarchart(user_action_freq_df,sort_by_col=\"duration_sec_sum\",y_col=\"action_distr\",\n",
    "                                    title=\"Stacked action freq per user - SORTED on total user video len (min)\",\n",
    "                                    xlabel=\"User idx - SORTED on total user video len (min) \",\n",
    "                                    ylabel=\"Stacked action freq\",\n",
    "                                    ):\n",
    "    df_sorted = user_action_freq_df.sort_values(by=[sort_by_col],ascending=False)\n",
    "    sorted_col_list = df_sorted[sort_by_col].tolist()\n",
    "    # print(df_sorted)\n",
    "\n",
    "    # Stack bar plots: \n",
    "    stack_user_counts_s = df_sorted[y_col].tolist()\n",
    "    check_sum_one(stack_user_counts_s)\n",
    "\n",
    "    # Transpose: List of 1st entries over users, list of 2nd entries, etc\n",
    "    stack_user_counts_st = np.asarray(stack_user_counts_s)\n",
    "    check_sum_one(stack_user_counts_st)\n",
    "    stack_user_counts_st = stack_user_counts_st.transpose()\n",
    "    print(f\"Stacked barchart plot entries (x=Users, y=user with max different actions)=({stack_user_counts_st.shape})\")\n",
    "\n",
    "    plt.figure(figsize=(20, 7), dpi=600) # So all bars are visible!\n",
    "    x_axis = list(range(len(stack_user_counts_st[0])))\n",
    "\n",
    "    # my_cmap = plt.get_cmap(\"hsv\")\n",
    "    my_cmap = plt.get_cmap(\"prism\")\n",
    "    color_steps = np.linspace(0, 1, len(stack_user_counts_st))\n",
    "\n",
    "    # Config\n",
    "    bar_width = 1\n",
    "\n",
    "    # First bar\n",
    "    prev_bar_values = stack_user_counts_st[0]\n",
    "    plt.bar(x_axis, height=prev_bar_values, align='center', width=bar_width,color=my_cmap(color_steps[0]))\n",
    "    for idx, stack_user_count in enumerate(stack_user_counts_st[1:]):\n",
    "        color = my_cmap(color_steps[idx+1])\n",
    "        plt.bar(x_axis, height=stack_user_count, color=color,bottom=prev_bar_values, align='center', width=bar_width)\n",
    "\n",
    "        assert len(prev_bar_values) == len(stack_user_count.tolist())\n",
    "        prev_bar_values = [x+y for x,y in zip(prev_bar_values,stack_user_count.tolist())]\n",
    "\n",
    "\n",
    "    plt.ylim(None,None)\n",
    "    plt.xlim(None,None)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    # plt.grid(grid)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    return sorted_col_list\n",
    "\n",
    "if EXECUTE:\n",
    "    video_lens_s = plot_useractions_stackedbarchart(user_action_freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5ea0b",
   "metadata": {},
   "source": [
    "# Plot barchart for total video length/user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e240188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video lengths for this plot\n",
    "# Barchart API: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html#matplotlib.pyplot.bar\n",
    "def plot_barchart(x_axis, y_vals, title,ylabel,xlabel='User-ID', \n",
    "                  grid=False,yerror=None,xerror=None, y_labels=None, x_labels=None,bar_align='edge',barh=False,\n",
    "                 figsize=(12, 6), log=False, interactive=False,x_minor_ticks=None):\n",
    "    max_val = max(y_vals)\n",
    "    my_cmap = plt.get_cmap(\"plasma\")\n",
    "    fig = plt.figure(figsize=figsize, dpi=600) # So all bars are visible!\n",
    "    ax=plt.subplot()\n",
    "    \n",
    "    if not barh:\n",
    "        bars = plt.bar(x_axis, height=y_vals,color=my_cmap.colors, align=bar_align,yerr=yerror,width=0.9,log=log)\n",
    "    else:\n",
    "        bars = plt.barh(y_vals, width=x_axis,color=my_cmap.colors, align=bar_align,xerr=xerror,height=0.9,log=log)\n",
    "    \n",
    "    if x_minor_ticks is not None:\n",
    "#         ax.set_xticks(major_ticks)\n",
    "        ax.set_xticks(x_minor_ticks, minor=True)\n",
    "#         ax.set_yticks(major_ticks)\n",
    "#         ax.set_yticks(minor_ticks, minor=True)\n",
    "\n",
    "        # And a corresponding grid\n",
    "#         ax.grid(which='both')\n",
    "\n",
    "#         # Or if you want different settings for the grids:\n",
    "#         ax.grid(which='minor', alpha=0.2)\n",
    "#         ax.grid(which='major', alpha=0.5)\n",
    "\n",
    "    if x_labels:\n",
    "        plt.xticks(x_axis, x_labels, rotation='vertical')\n",
    "    if y_labels:\n",
    "        plt.yticks(y_vals, y_labels)\n",
    "        \n",
    "\n",
    "    \n",
    "    plt.ylim(None,max_val*1.01)\n",
    "    plt.xlim(None,None)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(grid, which='both')\n",
    "    \n",
    "    if interactive:\n",
    "        annot = ax.annotate(\"\", xy=(0,0), xytext=(-20,20),textcoords=\"offset points\",\n",
    "                    bbox=dict(boxstyle=\"round\", fc=\"black\", ec=\"b\", lw=2),\n",
    "                    arrowprops=dict(arrowstyle=\"->\"))\n",
    "        annot.set_visible(False)\n",
    "        fig.canvas.mpl_connect(\"motion_notify_event\", hover)\n",
    "        \n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    print(f\"HEAD = {y_vals[:10]}...\")\n",
    "    print(f\"TAIL = ...{y_vals[-10:]}\")\n",
    "\n",
    "def update_annot(bar):\n",
    "    \"\"\" Interactive hovering: Change label visible \"\"\"\n",
    "    x = bar.get_x()+bar.get_width()/2.\n",
    "    y = bar.get_y()+bar.get_height()\n",
    "    annot.xy = (x,y)\n",
    "    text = \"({:.2g},{:.2g})\".format( x,y )\n",
    "    annot.set_text(text)\n",
    "    annot.get_bbox_patch().set_alpha(0.4)\n",
    "\n",
    "\n",
    "def hover(event):\n",
    "    \"\"\" Interactive hovering: hover event \"\"\"\n",
    "    vis = annot.get_visible()\n",
    "    if event.inaxes == ax:\n",
    "        for bar in bars:\n",
    "            cont, ind = bar.contains(event)\n",
    "            if cont:\n",
    "                update_annot(bar)\n",
    "                annot.set_visible(True)\n",
    "                fig.canvas.draw_idle()\n",
    "                return\n",
    "    if vis:\n",
    "        annot.set_visible(False)\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "if EXECUTE:\n",
    "    y_axis = [int(x/60) for x in video_lens_s]\n",
    "    x_axis = [idx for idx in range(len(video_lens_s))]\n",
    "    plot_barchart(x_axis, y_axis, title='Video length (min) per user',ylabel='Video length (min)',xlabel=\"user\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
