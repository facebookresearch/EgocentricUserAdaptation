TRAIN:
  ENABLE: True
  DATASET: Ego4dRecognition
  BATCH_SIZE: 64
DATA:
  PATH_TO_DATA_FILE: # Train on PRETRAIN data, and validate on USER-TRAIN SUBSET (which we use for hyperparam tuning)
#    TRAIN: "/home/matthiasdelange/sftp_remote_projects/ContextualOracle_Matthias/forecasting/continual_ego4d/usersplit_data/2022-07-27_21-05-14_ego4d_LTA_usersplit/ego4d_LTA_pretrain_usersplit_147users.json"
#    BUGGED JSON DIDNT INCLUDE NAN-USER: TRAIN: "/home/matthiasdelange/sftp_remote_projects/ContextualOracle_Matthias/forecasting/continual_ego4d/usersplit_data/2022-08-05_18-22-53_ego4d_LTA_usersplit/ego4d_LTA_pretrain_incl_nanusers_usersplit_148users.json"
    TRAIN: "/home/matthiasdelange/sftp_remote_projects/ContextualOracle_Matthias/forecasting/continual_ego4d/usersplit_data/2022-08-09_16-02-54_ego4d_LTA_usersplit/ego4d_LTA_pretrain_incl_nanusers_usersplit_148users.json"
    VAL: "/home/matthiasdelange/sftp_remote_projects/ContextualOracle_Matthias/forecasting/continual_ego4d/usersplit_data/2022-08-09_16-02-54_ego4d_LTA_usersplit/ego4d_LTA_train_usersplit_10users.json"
    TEST: "" # No testing anyway
  NUM_FRAMES: 32
  SAMPLING_RATE: 2
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_CROP_SIZE: 224
  TEST_CROP_SIZE: 256
  INPUT_CHANNEL_NUM: [3, 3]
  TASK: "classification"
  TARGET_FPS: 30
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
RESNET:
  ZERO_INIT_FINAL_BN: True
  WIDTH_PER_GROUP: 64
  NUM_GROUPS: 1
  DEPTH: 101
  TRANS_FUNC: bottleneck_transform
  STRIDE_1X1: False
  NUM_BLOCK_TEMP_KERNEL: [[3, 3], [4, 4], [23, 23], [3, 3]]
  SPATIAL_STRIDES: [[1, 1], [2, 2], [2, 2], [2, 2]]
  SPATIAL_DILATIONS: [[1, 1], [1, 1], [1, 1], [1, 1]]
NONLOCAL:
  LOCATION: [[[], []], [[], []], [[], []], [[], []]]
  GROUP: [[1, 1], [1, 1], [1, 1], [1, 1]]
  INSTANTIATION: softmax
BN:
  USE_PRECISE_STATS: True
  NUM_BATCHES_PRECISE: 20  # Originally 200 for full Ego4d, but have only 166 batches for subset
SOLVER:
  BASE_LR: 1e-4 # New attempt
  # 0.8: Slow-fast Kinetics-600, 1.6: for kinetics-400
  # Our attempt: 1e-3
  # Original Ego4d: 1e-4
  LR_POLICY: cosine # -> No linear warmup, get straight to it. Old: cosine_warmup
  MAX_EPOCH: 66
  MOMENTUM: 0.9
  OPTIMIZING_METHOD: sgd
  WEIGHT_DECAY: 1e-4
MODEL:
  NUM_CLASSES: [115, 478]
  ARCH: slowfast
  MODEL_NAME: MultiTaskSlowFast
  LOSS_FUNC: cross_entropy
  DROPOUT_RATE: 0.5
TEST:
  ENABLE: False
  DATASET: Ego4dRecognition
  BATCH_SIZE: 64
DATA_LOADER:
  NUM_WORKERS: 4
  PIN_MEMORY: True
NUM_GPUS: 8
NUM_SHARDS: 1
RNG_SEED: 0
OUTPUT_DIR: .
