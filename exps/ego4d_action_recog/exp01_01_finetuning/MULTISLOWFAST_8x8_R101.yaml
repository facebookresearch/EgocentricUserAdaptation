FAST_DEV_RUN: False
OUTPUT_DIR: "" # OVERWRITTEN IN CALLING-SCRIPT
RESUME_OUTPUT_DIR: "" # Specify with outputdir if want to resume, e.g. /path/to/logs/run_id/
CHECKPOINT_FILE_PATH: "" # For pretrained model to start from
CHECKPOINT_LOAD_MODEL_HEAD: True # Load population classifier
NUM_USERS_PER_DEVICE: 1
METHOD:
  METHOD_NAME: "Finetuning"
TEST:
  ENABLE: False
CONTINUAL_EVAL:
  FREQ: 1
  BATCH_SIZE: 10 # For speedup with parallel dataloading
  FUTURE_SAMPLE_CAPACITY: 100
  PAST_SAMPLE_CAPACITY: 100
TRAIN:
  ENABLE: True
  DATASET: Ego4dContinualRecognition
  BATCH_SIZE: 4 # Process 1 new video-subsequence a time (Online)
DATA:
  USER_SUBSET: 'train' # train or test usersplit
  PATH_TO_DATA_SPLIT_JSON:
    TRAIN_SPLIT: '/home/matthiasdelange/sftp_remote_projects/ContextualOracle_Matthias/forecasting/continual_ego4d/usersplit_data/2022-08-09_16-02-54_ego4d_LTA_usersplit/ego4d_LTA_train_usersplit_10users.json'
    TEST_SPLIT: '/home/matthiasdelange/sftp_remote_projects/ContextualOracle_Matthias/forecasting/continual_ego4d/usersplit_data/2022-08-09_16-02-54_ego4d_LTA_usersplit/ego4d_LTA_test_usersplit_40users.json'
    PRETRAIN_SPLIT: '/home/matthiasdelange/sftp_remote_projects/ContextualOracle_Matthias/forecasting/continual_ego4d/usersplit_data/2022-08-09_16-02-54_ego4d_LTA_usersplit/ego4d_LTA_pretrain_incl_nanusers_usersplit_148users.json'
  TARGET_FPS: 30
  NUM_FRAMES: 32
  SAMPLING_RATE: 2
  TRAIN_JITTER_SCALES: [ 256, 320 ]
  TRAIN_CROP_SIZE: 224
  TEST_CROP_SIZE: 256
  INPUT_CHANNEL_NUM: [ 3, 3 ]
  TASK: "continual_classification"
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
RESNET:
  ZERO_INIT_FINAL_BN: True
  WIDTH_PER_GROUP: 64
  NUM_GROUPS: 1
  DEPTH: 101
  TRANS_FUNC: bottleneck_transform
  STRIDE_1X1: False
  NUM_BLOCK_TEMP_KERNEL: [ [ 3, 3 ], [ 4, 4 ], [ 23, 23 ], [ 3, 3 ] ]
  SPATIAL_STRIDES: [ [ 1, 1 ], [ 2, 2 ], [ 2, 2 ], [ 2, 2 ] ]
  SPATIAL_DILATIONS: [ [ 1, 1 ], [ 1, 1 ], [ 1, 1 ], [ 1, 1 ] ]
NONLOCAL:
  LOCATION: [ [ [ ], [ ] ], [ [ ], [ ] ], [ [ ], [ ] ], [ [ ], [ ] ] ]
  GROUP: [ [ 1, 1 ], [ 1, 1 ], [ 1, 1 ], [ 1, 1 ] ]
  INSTANTIATION: softmax
BN:
  USE_PRECISE_STATS: False # Not for CL
#  NUM_BATCHES_PRECISE: 200 # After this many batches, Recomputes Batch-stats on actual fixed model instead of running avg
SOLVER:
  BASE_LR: 1e-4
  LR_POLICY: constant
  MAX_EPOCH: 1
  MOMENTUM: 0.9
  OPTIMIZING_METHOD: sgd
  WEIGHT_DECAY: 0.0
MODEL:
  NUM_CLASSES: [ 115, 478 ] # Verbs, nouns
  ARCH: slowfast
  MODEL_NAME: MultiTaskSlowFast
  LOSS_FUNC: cross_entropy
  DROPOUT_RATE: 0.5
DATA_LOADER:
  NUM_WORKERS: 16
  PIN_MEMORY: True
NUM_GPUS: 1
NUM_SHARDS: 1
RNG_SEED: 0

